testResults
set.seed(100)
svmRTune <- train(Yield ~., data = trainSet,
method = "svmRadial",
preProc = c("center", "scale"),
tuneLength = 14,
trControl = cntrl)
svmRTune
plot(svmRTune, scales = list(x = list(log = 2)))
plot(svmRTune, scales = list(x = list(log = 2)))
svmRTune$finalModel
testResults <- data.frame(obs = test_y,
SVMr = predict(svmRTune, testSet))
testResults
plot(marsTune)
# final values of the tuning parameters (degree and nprune) that resulted in the best performance during cross-validation
marsTune$finalModel
testResults <- data.frame(obs = test_y,
MARs = predict(marsTune, testSet))
testResults
svmGrid <- expand.grid(degree = 1:2,
scale = c(0.01, 0.005, 0.001),
C = 2^(-2:5))
set.seed(100)
svmPTune <- train(Yield ~., data = trainSet,
method = "svmPoly",
preProc = c("center", "scale"),
tuneGrid = svmGrid,
trControl = cntrl)
svmPTune
plot(svmPTune,
scales = list(x = list(log = 2),
between = list(x = .5, y = 1)))
plot(svmPTune,
scales = list(x = list(log = 2),
between = list(x = .5, y = 1)))
svmPTune$finalModel
testResults <- data.frame(obs = test_y,
SVMp = predict(svmPTune, testSet))
testResults
knnDescr <- trainSet[, -nearZeroVar(trainSet)]
knnDescr
trainSet
knntrainSet <- trainSet[, -nearZeroVar(trainSet)] # one column removed
set.seed(100)
knnTune <- train(Yield ~ ., data = knntrainSet,
method = "knn",
tuneGrid = data.frame(k = 1:20),
trControl = cntrl)
knnTune
knntrainSet <- trainSet[, -nearZeroVar(trainSet)] # one column removed
set.seed(100)
knnTune <- train(Yield ~ ., data = knntrainSet,
method = "knn",
tuneGrid = data.frame(k = 1:25),
trControl = cntrl)
knnTune
knntrainSet <- trainSet[, -nearZeroVar(trainSet)] # one column removed
set.seed(100)
knnTune <- train(Yield ~ ., data = knntrainSet,
method = "knn",
tuneGrid = data.frame(k = 1:10),
trControl = cntrl)
knnTune
plot(knnTune)
knnTune$finalModel
testResults <- data.frame(obs = test_y,
kNN = predict(knnTune, testSet))
plot(knnTune)
knnTune$finalModel
testResults <- data.frame(obs = test_y,
kNN = predict(knnTune, testSet))
testResults
predictions <- predict(knnTune, newdata = testSet)
predictions
predictions <- predict(knnTune, newdata = testSet)
predictions
plot(knnTune)
knnTune$finalModel
testResults <- data.frame(obs = test_y,
kNN = predict(knnTune, testSet))
testResults
predictions <- predict(knnTune, newdata = testSet)
predictions
# Predict on test set
predictions_nnetTune <- predict(nnetTune, newdata = testSet[-"Yield"])
library(AppliedPredictiveModeling)
data(solubility)
solTrainY
library(AppliedPredictiveModeling)
data(solubility)
solTrainY
solTrainXtrans
solTetsY
solTestY
solubility
# data Splitting
set.seed(100)
# split the data
trainIndex <- createDataPartition(data$Yield, p = .8, list = FALSE)
trainSet <- data[trainIndex, ]
testSet  <- data[-trainIndex, ]
test_y <- testSet$Yield  # Save the 'Yield' from test set
testSet$Yield <- NULL  # Exclude 'Yield' from testSet
testSet
# preprocess the data by centering and scaling
preProcessData <- preProcess(trainSet, method = c("center", "scale"))
trainSet <- predict(preProcessData, trainSet )
testSet <- predict(preProcessData, testSet )
testSet
# data Splitting
set.seed(100)
# split the data
trainIndex <- createDataPartition(data$Yield, p = .8, list = FALSE)
trainSet <- data[trainIndex, ]
testSet  <- data[-trainIndex, ]
test_y <- testSet$Yield  # Save the 'Yield' from test set
testSet$Yield <- NULL  # Exclude 'Yield' from testSet
testSet
# preprocess the data by centering and scaling
preProcessData <- preProcess(trainSet, method = c("center", "scale"))
trainSet <- predict(preProcessData, trainSet )
testSet <- predict(preProcessData, testSet )
# data Splitting
set.seed(100)
trainIndex <- createDataPartition(data$Yield, p = .8, list = FALSE)
trainData <- data[trainIndex, ]
testData  <- data[-trainIndex, ]
train_X <- trainData[ , !(names(trainData) %in% "Yield")]
train_y <- trainData$Yield
test_X <- testData[ , !(names(testData) %in% "Yield")]
test_y <- testData$Yield
preProcessData <- preProcess(train_X, method = c("center", "scale"))
train_X <- predict(preProcessData, train_X)
test_X <- predict(preProcessData, test_X)
cntrl <- trainControl(method = "cv", number = 10)
nnetGrid <- expand.grid(decay = c(0, 0.01, .1),
size = c(3, 7, 11, 13))
set.seed(100)
nnetTune <- train(x = train_X, y = train_y,
method = "nnet",
tuneGrid = nnetGrid,
trControl = cntrl,
linout = TRUE,
trace = FALSE,
MaxNWts = 15 * (ncol(trainSet) - 1) + 10 + 1, # (ncol(trainSet) - 1) because, including the response variable 'Yield' in trainSet and we don't want to count the target variable as an input to the network. So, we subtract one for the target variable 'Yield'.
maxit = 1000)
nnetTune
plot(nnetTune)
nnetTune$finalModel
# response variable
testResults <- data.frame(obs = test_y,
NNet = predict(nnetTune, test_X))
testResults
set.seed(100)
marsTune <- train(x = train_X, y = train_y,
method = "earth",
tuneGrid = expand.grid(degree = 1, nprune = 2:38),
trControl = cntrl)
marsTune
plot(marsTune)
# final values of the tuning parameters (degree and nprune) that resulted in the best performance during cross-validation
marsTune$finalModel
testResults <- data.frame(obs = test_y,
MARS = predict(marsTune, test_X))
testResults
set.seed(100)
svmRTune <- train(x = train_X, y = train_y,
method = "svmRadial",
preProc = c("center", "scale"),
tuneLength = 14,
trControl = cntrl)
svmRTune
plot(svmRTune, scales = list(x = list(log = 2)))
svmRTune$finalModel
testResults <- data.frame(obs = test_y,
SVMr = predict(svmRTune, test_X))
testResults
svmGrid <- expand.grid(degree = 1:2,
scale = c(0.01, 0.005, 0.001),
C = 2^(-2:5))
set.seed(100)
svmPTune <- train(x = train_X, y = train_y,
method = "svmPoly",
preProc = c("center", "scale"),
tuneGrid = svmGrid,
trControl = cntrl)
svmPTune
plot(svmPTune,
scales = list(x = list(log = 2),
between = list(x = .5, y = 1)))
svmPTune$finalModel
testResults <- data.frame(obs = test_y,
SVMp = predict(svmPTune, test_X))
testResults
knntrainSet <- train_X[, -nearZeroVar(train_X)] # one column removed
set.seed(100)
knnTune <- train(x = train_X, y = train_y,
method = "knn",
tuneGrid = data.frame(k = 1:10),
trControl = cntrl)
knnTune
plot(knnTune)
knnTune$finalModel
testResults <- data.frame(obs = test_y,
kNN = predict(knnTune, test_X))
testResults
# Predict on test set
predictions_nnetTune <- predict(nnetTune, newdata = test_X)
predictions_nnetTune
testRMSE_nnetTune <- sqrt(mean((predictions_nnetTune - test_y)^2))
testRMSE_nnetTune <- sqrt(mean((predictions_nnetTune - test_y)^2))
testRMSE_nnetTune
# Predict on test set
predictions_nnetTune <- predict(nnetTune, newdata = test_X)
predictions_marsTune <- predict(marsTune, newdata = test_X)
predictions_svmRTune <- predict(svmRTune, newdata = test_X)
predictions_smvPTune <- predict(smvPTune, newdata = test_X)
# Predict on test set
predictions_nnetTune <- predict(nnetTune, newdata = test_X)
predictions_marsTune <- predict(marsTune, newdata = test_X)
predictions_svmRTune <- predict(svmRTune, newdata = test_X)
predictions_svmPTune <- predict(svmPTune, newdata = test_X)
predictions_knnTune <- predict(knnTune, newdata = test_X)
# RMSE performance on test dataset
testRMSE_nnetTune <- sqrt(mean((predictions_nnetTune - test_y)^2))
testRMSE_marsTune <- sqrt(mean((predictions_marsTune - test_y)^2))
testRMSE_svmRTune <- sqrt(mean((predictions_svmRTune - test_y)^2))
testRMSE_svmPTune <- sqrt(mean((predictions_svmPTune - test_y)^2))
testRMSE_knnTune <- sqrt(mean((predictions_knnTune - test_y)^2))
# Creating dataframe
testRMSE_df <- data.frame(
Model = c("Neural Network", "MARS", "SVM Radial", "SVM Polynomial", "KNN"),
RMSE = c(testRMSE_nnetTune, testRMSE_marsTune, testRMSE_svmRTune, testRMSE_svmPTune, testRMSE_knnTune)
)
testRMSE_df
nnetImp <- varImp(nnetTune, scale = FALSE)
plot(nnetImp, top = 10)
library(AppliedPredictiveModeling)
data("ChemicalManufacturingProcess")
# check missing values
sum(is.na(ChemicalManufacturingProcess))
# impute missing values with k-nearest neighbors
no_missing_data <- preProcess(ChemicalManufacturingProcess, method = 'knnImpute')
data <- predict(no_missing_data, newdata = ChemicalManufacturingProcess)
# check missing values
sum(is.na(data))
# data Splitting
set.seed(100)
# split the data
trainIndex <- createDataPartition(data$Yield, p = .8, list = FALSE)
trainSet <- data[trainIndex, ]
testSet  <- data[-trainIndex, ]
# preprocess the data by centering and scaling
preProcValues_train <- preProcess(trainSet, method = c("center", "scale"))
preProcValues_test <- preProcess(testSet, method = c("center", "scale"))
trainSet <- predict(preProcValues_train, trainSet )
cntrl <- trainControl(method = "cv", number = 10)
####################################################### Lasso Regression
alpha <- 1 # If alpha is 1, the method performs Lasso regression
lambda <- 10^seq(-3, 3, length = 100) # lambda values
lassoGrid <- expand.grid(alpha = alpha, lambda = lambda)
set.seed(100)
lasso_reg <- train(Yield ~ ., data = trainSet,
method = "glmnet",
tuneGrid = lassoGrid,
trControl = cntrl)
#lasso_reg
####################################################### Partial Least Squares (PLS)
set.seed(100)
partial_leasts <- train(Yield ~ ., data = trainSet,
method = "pls",
tuneGrid = expand.grid(ncomp = 1:10),
trControl = cntrl)
#partial_leasts
####################################################### Ridge Regression
ridgeGrid <- data.frame(.lambda = seq(0, 0.1, length = 15))
set.seed(100)
ridge_reg <- train(Yield ~ ., data = trainSet,
method = "ridge",
tuneGrid = ridgeGrid,
trControl = cntrl)
#ridge_reg
####################################################### elastic net
enetGrid <- expand.grid(.lambda = c(0, 0.01, 0.1),
.fraction = seq(0.05, 1, length = 20))
set.seed(100)
elastic_net <- train(Yield ~ ., data = trainSet,
method = "enet",
tuneGrid = enetGrid,
trControl = cntrl)
#elastic_net
# optimal RMSE and corresponding models
print(paste("Lasso optimal RMSE: ", min(lasso_reg$results$RMSE)))
print(paste("Ridge optimal RMSE: ", min(ridge_reg$results$RMSE)))
print(paste("PLS optimal RMSE: ", min(partial_leasts$results$RMSE)))
print(paste("Elastic net optimal RMSE: ", min(elastic_net$results$RMSE)))
# make predictions
predictions_pls <- predict(partial_leasts, newdata = testSet)
predictions_ridge <- predict(ridge_reg, newdata = testSet)
predictions_lasso <- predict(lasso_reg, newdata = testSet)
predictions_enet <- predict(elastic_net, newdata = testSet)
# calculate RMSE
test_RMSE_lasso <- RMSE(predictions_lasso, testSet$Yield)
test_RMSE_ridge <- RMSE(predictions_ridge, testSet$Yield)
test_RMSE_pls <- RMSE(predictions_pls, testSet$Yield)
test_RMSE_enet <- RMSE(predictions_enet, testSet$Yield)
print(paste("Lasso test set RMSE: ", test_RMSE_lasso))
print(paste("Ridge test set RMSE: ", test_RMSE_ridge))
print(paste("PLS test set RMSE: ", test_RMSE_pls))
print(paste("Elastic net test set RMSE: ", test_RMSE_enet))
# final model is Lasso regression based on the RMSE
final_model <- lasso_reg$finalModel
# the optimal lambda value
opt_lambda <- lasso_reg$bestTune$lambda
coef_matrix <- coef(final_model, s = opt_lambda)
coef_matrix <- as.matrix(coef_matrix)
coef_matrix
# names of variables with non-zero coefficient
important_variables <- rownames(coef_matrix)[coef_matrix[,1] != 0]
important_variables
lassoImp <- varImp(lasso_reg, scale = FALSE)
plot(lassoImp, top = 10)
library(mlbench)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
library(mlbench)
set.seed(200)
simulated <- mlbench.friedman1(200, sd = 1)
simulated <- cbind(simulated$x, simulated$y)
simulated <- as.data.frame(simulated)
colnames(simulated)[ncol(simulated)] <- "y"
simulated
library(randomForest)
library(caret)
model1 <- randomForest(y ~ ., data = simulated, importance = TRUE, ntree = 1000)
varImp(model1)
library(randomForest)
library(caret)
model1 <- randomForest(y ~ ., data = simulated, importance = TRUE, ntree = 1000)
varImp(model1)
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1
simulated$duplicate1 <- simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
simulated2 <- simulated
simulated$duplicate1 <- simulated2 + simulated$V1 + rnorm(200) * .1
cor(simulated$duplicate1, simulated$V1)
library(randomForest)
library(caret)
model2 <- randomForest(y ~ ., data = simulated2, importance = TRUE, ntree = 1000)
varImp(model2)
simulated2
simulated2 <- simulated
simulated$duplicate1 <- simulated2 + simulated$V1 + rnorm(200) * .1
cor(simulated2$duplicate1, simulated2$V1)
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling")   #choose a location/path and set the working directory
source ("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline/Data_Ingestion.R")
source ("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline/Viz_EDA.R")
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
head(cervical_data_raw,5)
# check missing data
null_counts <- check_nulls(cervical_data_raw)
# remove cols with more than 50% missing data
cervical_data_clean <- remove_cols(cervical_data_raw)
# check missing data
null_counts <- check_nulls(cervical_data_clean)
# check the column distribution- columns[2:9]
plot_distributions(cervical_data_clean, 2:9)
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling")   #choose a location/path and set the working directory
source ("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline/Data_Ingestion.R")
source ("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline/Viz_EDA.R")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/Pipeline")   #choose a location/path and set the working directory
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling")   #choose a location/path and set the working directory
source ("Pipeline/Data_Ingestion.R")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
source ("Viz_EDA.R")
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
head(cervical_data_raw,5)
# check missing data
null_counts_raw <- check_nulls(cervical_data_raw)
# remove cols with more than 50% missing data
cervical_data_clean <- remove_cols(cervical_data_raw)
# check missing data
null_counts_clean <- check_nulls(cervical_data_clean)
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
df <- df[, !(names(df) %in% cols_to_remove)]
install.packages("DMwR")
library(DMwR)
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
head(cervical_data_raw,5)
# check missing data
null_counts_raw <- check_nulls(cervical_data_raw)
# remove cols with more than 50% missing data
cervical_data_clean <- remove_cols(cervical_data_raw)
# check missing data
null_counts_clean <- check_nulls(cervical_data_clean)
# check the column distribution- columns[2:9]
plot_distributions(cervical_data_clean, 2:9)
# These user-defined functions are pulled from the Viz_EDA.R file.
# Look at all histograms of features collectively
hist.df(cervical_data_clean)
# Create boxplots for all features - helps visualize outliers
boxplot.df(cervical_data_clean)
library(caret)
# Remove near zero variance variables
dim(cervical_data_clean)
degeneratecols <- nearZeroVar(cervical_data_clean)
length(degeneratecols)
cervical_data_process <- cervical_data_clean[, -degeneratecols]
dim(cervical_data_process)
# Do KNN imputation, centering, and scaling
preprocess <- preProcess(cervical_data_process, method = c("knnImpute", "center", "scale"))
cervical_data_process <- predict(preprocess, cervical_data_process)
# check missing data
null_counts_process <- check_nulls(cervical_data_process)
dim(cervical_data_process)
length(degeneratecols)
install.packages("DMwR")
library(DMwR)
########################################################### impute missing data using knn imputation
install.packages("VIM")
# Function to impute NA values with kNN imputation
impute_with_knn <- function(df, k = 6) {
df_imputed <- kNN(df, k = k)  # Perform kNN imputation
return(df_imputed)
}
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
source ("Viz_EDA.R")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
source ("Viz_EDA.R")
install.packages("VIM")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
source ("Viz_EDA.R")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
source ("Viz_EDA.R")
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
set.seed(007)
read_data <- function(x) {
# will read data from input folder
# used na.strings = "?" for the null values. The null values are stored as "?" in the dataset.
cervical_data_raw <- read.csv(x, na.strings = "?")
glimpse(cervical_data_raw)
return(cervical_data_raw)
}
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
source ("Viz_EDA.R")
install.packages("VIM")
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
source ("Viz_EDA.R")
install.packages("VIM")
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
# Uses functions from files loaded in to clean data
set.seed(007)
# loading Data
cervical_data_raw <- read_data(x="/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/input_resource/kag_risk_factors_cervical_cancer.csv")
library(dplyr)
setwd("/Users/ruddysimonpour/Desktop/University of Sandiego - Curriculum/ADS 503 - Applied Predictive Modeling/ADS503-Applied-Predictive-Modeling/Pipeline")   #choose a location/path and set the working directory
source ("Data_Ingestion.R")
